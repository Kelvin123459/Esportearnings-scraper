{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esportsearning.com website scraper\n",
    "#### Author: Kelvin García Muñiz\n",
    "***\n",
    "This notebook was created to scrape data from the website [esportsearnings.com](https://www.esportsearnings.com/) to perform a data analysis study. This was done using primarily the [Selenium library](https://selenium-python.readthedocs.io/) with the assistance of [BeautifulSoup](https://beautiful-soup-4.readthedocs.io/en/latest/index.html?highlight=find_all#). \n",
    "\n",
    "The scraper produces .csv files, each corresponding to the following data:\n",
    ">1. [Video Games Data](#section1)\n",
    ">2. [Players Data](#section2)\n",
    ">3. [Esports Teams Data](#section3)\n",
    ">4. [Participant Countries Data](#section4)\n",
    "\n",
    "To view the analysis head over to the corresponding Github Repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Dataframes function\n",
    "\n",
    "The make_df function generates a dataframe format depending on the data to scrap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(data):\n",
    "    if data == \"games\":\n",
    "        print(\"True\")\n",
    "        df = pd.DataFrame(columns=['Game','Prize', 'NumPlayer', 'NumTournaments', 'Year'])\n",
    "        return df\n",
    "    elif data == \"players\":\n",
    "        df = pd.DataFrame(columns=['Username','Name', 'Country', 'Prize', 'Year'])\n",
    "        return df\n",
    "    elif data == \"teams\":\n",
    "        df = pd.DataFrame(columns=['Team', 'Prize', 'NumTournaments', 'Year'])\n",
    "        return df\n",
    "    elif data == \"countries\":\n",
    "        df = pd.DataFrame(columns=['Country', 'Prize', 'NumPlayers', 'Year'])\n",
    "        return df\n",
    "    else:\n",
    "        print(\"Error: The data to scrape is not an option\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following variables determine the starting year for the analysis and the range of years to analyze. They are accessible for easy changes to the scope of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_year = 2002\n",
    "year_range = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Games Data\n",
    "<a id=\"section1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()\n",
    "df = make_df(\"games\")\n",
    "if(df.empty): #if the dataframe is not empty then run\n",
    "    for year in range(year_range):\n",
    "        urlYear = str(starting_year+year)\n",
    "        url = \"https://www.esportsearnings.com/history/\" + urlYear + \"/games\"\n",
    "        \n",
    "        driver.get(url)\n",
    "\n",
    "        games = driver.find_elements(By.CLASS_NAME, \"detail_list_player\")\n",
    "        data = driver.find_elements(By.CLASS_NAME, \"detail_list_prize\") #the rest of the information is all contained under the same label\n",
    "        gamesList = []\n",
    "        prizesList = []\n",
    "        numPlayersList = []\n",
    "        tournamentsList = []\n",
    "        for game in range(len(games)):\n",
    "            gamesList.append(games[game].text)\n",
    "        i = 7\n",
    "        while i<(len(data)-20): #the website uses the same label to showcase other information. The \"-20\" attends to such scenario\n",
    "            prizesList.append(data[i].text)\n",
    "            numPlayersList.append(data[i+1].text)\n",
    "            tournamentsList.append(data[i+2].text)\n",
    "            i+=3\n",
    "        data_tuples = list(zip(gamesList[0:],prizesList[0:], numPlayersList[0:], tournamentsList[0:])) # list of each players name and salary paired together\n",
    "        temp_df = pd.DataFrame(data_tuples, columns=['Game','Prize', 'NumPlayer', 'NumTournaments']) # creates dataframe of each tuple in list\n",
    "        temp_df['Year'] = urlYear # adds season beginning year to each dataframe\n",
    "        df = df.append(temp_df) # appends to master dataframe\n",
    "            # display(df)\n",
    "    driver.close()\n",
    "    display(df)\n",
    "    df.to_csv(\"gamesData.csv\")\n",
    "else:\n",
    "    driver.close()\n",
    "    print(\"\\tCheck make_df function argument\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Players Data\n",
    "<a id=\"section2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()\n",
    "df = make_df(\"players\")\n",
    "if(df.empty): #if the dataframe is not empty then run\n",
    "    for year in range(year_range):\n",
    "        urlYear = str(starting_year+year)\n",
    "        url = \"https://www.esportsearnings.com/history/\" + urlYear + \"/top_players\"\n",
    "        \n",
    "        driver.get(url)\n",
    "        response = requests.get(url) #to be used by BS\n",
    "\n",
    "        #the names of the countries are displayed in the website as flag images\n",
    "        soup = BeautifulSoup(response.content, 'html.parser') #here we use BS since the selenium could not separate the title of the image from the data selected.\n",
    "        results = soup.find_all(\"img\")\n",
    "\n",
    "        playerList = driver.find_elements(By.CLASS_NAME, \"detail_list_player\")\n",
    "        data = driver.find_elements(By.CLASS_NAME, \"detail_list_prize\") #the rest of the information is all contained under the same label\n",
    "        playerUserList = []\n",
    "        playerNameList = []\n",
    "        prizesList = []\n",
    "        countryList = []\n",
    "        for i in results:\n",
    "            countryList.append(i.get('title')) # gets the title property from the BS response\n",
    "        i = 0\n",
    "        while i<(len(playerList)-1):\n",
    "            playerUserList.append(playerList[i].text)\n",
    "            playerNameList.append(playerList[i+1].text)\n",
    "            i+=2\n",
    "\n",
    "        j = 7\n",
    "        while j<(len(data)-20): #the website uses the same label to showcase other information. The \"-20\" attends to such scenario\n",
    "            prizesList.append(data[j].text)\n",
    "            j+=3\n",
    "        \n",
    "        data_tuples = list(zip(playerUserList[0:], playerNameList[0:], countryList[0:], prizesList[0:])) # list of each players name and salary paired together\n",
    "        temp_df = pd.DataFrame(data_tuples, columns=['Username','Name', 'Country', 'Prize']) # creates dataframe of each tuple in list\n",
    "        temp_df['Year'] = urlYear # adds season beginning year to each dataframe\n",
    "        df = df.append(temp_df) # appends to master dataframe\n",
    "        # display(df)\n",
    "\n",
    "    driver.close()\n",
    "    display(df)\n",
    "    df.to_csv(\"playerData.csv\")\n",
    "else:\n",
    "    driver.close()\n",
    "    print(\"\\tCheck make_df function argument\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Teams Data\n",
    "<a id=\"section3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()\n",
    "df = make_df(\"teams\")\n",
    "if(df.empty): #if the dataframe is not empty then run\n",
    "    for year in range(year_range):\n",
    "        urlYear = str(starting_year+year)\n",
    "        url = \"https://www.esportsearnings.com/history/\" + urlYear + \"/teams\"\n",
    "        \n",
    "        driver.get(url)\n",
    "\n",
    "        teams = driver.find_elements(By.CLASS_NAME, \"detail_list_player\")\n",
    "        data = driver.find_elements(By.CLASS_NAME, \"detail_list_prize\") #the rest of the information is all contained under the same label\n",
    "        teamsList = []\n",
    "        prizesList = []\n",
    "        tournamentsList = []\n",
    "        for team in range(len(teams)):\n",
    "            teamsList.append(teams[team].text)\n",
    "        i = 7\n",
    "        while i<(len(data)-20): #the website uses the same label to showcase other information. The \"-20\" attends to such scenario\n",
    "            prizesList.append(data[i].text)\n",
    "            tournamentsList.append(data[i+1].text)\n",
    "            i+=2\n",
    "        data_tuples = list(zip(teamsList[0:],prizesList[0:], tournamentsList[0:])) # list of each players name and salary paired together\n",
    "        temp_df = pd.DataFrame(data_tuples, columns=['Team','Prize', 'NumTournaments']) # creates dataframe of each tuple in list\n",
    "        temp_df['Year'] = urlYear # adds season beginning year to each dataframe\n",
    "        df = df.append(temp_df) # appends to master dataframe\n",
    "            # display(df)\n",
    "    driver.close()\n",
    "    display(df)\n",
    "    df.to_csv(\"teamsData.csv\")\n",
    "else:\n",
    "    driver.close()\n",
    "    print(\"\\tCheck make_df function argument\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Countries Data\n",
    "<a id=\"section4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()\n",
    "df = make_df(\"countries\")\n",
    "if(df.empty): #if the dataframe is not empty then run\n",
    "    for year in range(year_range):\n",
    "        urlYear = str(starting_year+year)\n",
    "        url = \"https://www.esportsearnings.com/history/\" + urlYear + \"/countries\"\n",
    "        \n",
    "        driver.get(url)\n",
    "\n",
    "        countries = driver.find_elements(By.CLASS_NAME, \"detail_list_player\")\n",
    "        data = driver.find_elements(By.CLASS_NAME, \"detail_list_prize\") #the rest of the information is all contained under the same label\n",
    "        countryList = []\n",
    "        prizesList = []\n",
    "        playersList = []\n",
    "        for country in range(len(countries)):\n",
    "            countryList.append(countries[country].text)\n",
    "        i = 7\n",
    "        while i<(len(data)-20): #the website uses the same label to showcase other information. The \"-20\" attends to such scenario\n",
    "            prizesList.append(data[i].text)\n",
    "            playersList.append(data[i+1].text)\n",
    "            i+=2\n",
    "        data_tuples = list(zip(countryList[0:],prizesList[0:], playersList[0:])) # list of each players name and salary paired together\n",
    "        temp_df = pd.DataFrame(data_tuples, columns=['Country','Prize', 'NumPlayers']) # creates dataframe of each tuple in list\n",
    "        temp_df['Year'] = urlYear # adds season beginning year to each dataframe\n",
    "        df = df.append(temp_df) # appends to master dataframe\n",
    "            # display(df)\n",
    "    driver.close()\n",
    "    display(df)\n",
    "    df.to_csv(\"countriesData.csv\")\n",
    "else:\n",
    "    driver.close()\n",
    "    print(\"\\tCheck make_df function argument\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References: \n",
    "> 1. [Bryan Pfalzgraf via Medium](https://towardsdatascience.com/how-to-use-selenium-to-web-scrape-with-example-80f9b23a843a)\n",
    "> 2. [Selenium Documentation](https://selenium-python.readthedocs.io/)\n",
    "> 3. [Beautiful Soup](https://beautiful-soup-4.readthedocs.io/en/latest/index.html?highlight=find_all#find-all)\n",
    "> 4. [Stack Overflow](https://stackoverflow.com/)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43ac2302dbdc091d64cae5c37f2bd3650672b0961ebe5b52ceebd004e80dd3a8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
